{"cells":[{"cell_type":"code","source":["def clean_column_names(df):\n  tempList = [] #Edit01\n  for col in df.columns:\n      new_name = col.strip()\n      new_name = \"\".join(new_name.split())\n      new_name = new_name.replace('.','') \n      tempList.append(new_name) \n\n  return df.toDF(*tempList) \n\n#%pip install sparkmeasure\nfrom sparkmeasure import StageMetrics\nstagemetrics = StageMetrics(spark)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc589373-7e4e-489c-9e1f-587ea3ab7b58"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Question 1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"deb78301-7558-46ae-9a97-59dfc463aa77"}}},{"cell_type":"markdown","source":["Question 1A Angelina Sun 500521854"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1cdfd2d1-c449-4c15-99a5-b5a61223d36e"}}},{"cell_type":"code","source":["def part1_QA(spark_session, flights_path, aircrafts_path):\n    from pyspark.sql import functions as F # import library\n    \n    #import dataset\n    flights = spark_session.read.csv(flights_path,\n                                        inferSchema=True,\n                                        header=True)\n    aircrafts = spark_session.read.csv(aircrafts_path,\n                                        inferSchema=True,\n                                        header=True)\n    \n    #cleaning variable names\n    aircraft = aircrafts.select(F.col(\"tailnum\").alias(\"tail_number\"),F.col(\"year\"))\n    flight = flights.select(F.col(\" tail_number\").alias(\"tail_number\"),F.col(\" flight_number\").alias(\"flight_number\"))\n    \n    join_df = flight.join(aircraft, \"tail_number\", \"inner\") # inner join between two dataframe\n    count_df = join_df.groupBy(\"year\").count().dropna() #group by year; count how many flights for each year; Drop null values\n    sort_df = count_df.orderBy(\"count\", ascending = False).limit(1).collect() # sort in decending order\n    \n    # print output\n    for (year, count) in sort_df:\n        print(\"%s had %s flights.\" % (year, count))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d0b6928-3154-49c3-b8f5-9de70a0223e2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\npart1_QA(spark, \"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\", \"dbfs:/FileStore/tables/ontimeperformance_aircrafts.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cbc48e63-6105-4bb2-82fa-8a9f3d6793cd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"2001 had 7618 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 7\nnumTasks => 11\nelapsedTime => 6357 (6 s)\nstageDuration => 4922 (5 s)\nexecutorRunTime => 8642 (9 s)\nexecutorCpuTime => 2167 (2 s)\nexecutorDeserializeTime => 953 (1.0 s)\nexecutorDeserializeCpuTime => 329 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 86 (86 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 83 (83 ms)\nresultSize => 33827 (33.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 51904512\nrecordsRead => 330529\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 132\nshuffleTotalBlocksFetched => 3\nshuffleLocalBlocksFetched => 3\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 8933 (8.0 KB)\nshuffleLocalBytesRead => 8933 (8.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 8933 (8.0 KB)\nshuffleRecordsWritten => 132\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["2001 had 7618 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 7\nnumTasks => 11\nelapsedTime => 6357 (6 s)\nstageDuration => 4922 (5 s)\nexecutorRunTime => 8642 (9 s)\nexecutorCpuTime => 2167 (2 s)\nexecutorDeserializeTime => 953 (1.0 s)\nexecutorDeserializeCpuTime => 329 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 86 (86 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 83 (83 ms)\nresultSize => 33827 (33.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 51904512\nrecordsRead => 330529\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 132\nshuffleTotalBlocksFetched => 3\nshuffleLocalBlocksFetched => 3\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 8933 (8.0 KB)\nshuffleLocalBytesRead => 8933 (8.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 8933 (8.0 KB)\nshuffleRecordsWritten => 132\n"]}}],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\npart1_QA(spark, \"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\", \"dbfs:/FileStore/tables/ontimeperformance_aircrafts.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cccb1c2f-d317-48c1-8b0c-374e538d8490"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"2001 had 76370 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 7\nnumTasks => 21\nelapsedTime => 19236 (19 s)\nstageDuration => 17758 (18 s)\nexecutorRunTime => 117292 (2.0 min)\nexecutorCpuTime => 14563 (15 s)\nexecutorDeserializeTime => 993 (1.0 s)\nexecutorDeserializeCpuTime => 241 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 1572 (2 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 323 (0.3 s)\nresultSize => 33827 (33.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138412032\nrecordsRead => 3209457\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 299\nshuffleTotalBlocksFetched => 7\nshuffleLocalBlocksFetched => 7\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 20360 (19.0 KB)\nshuffleLocalBytesRead => 20360 (19.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 20360 (19.0 KB)\nshuffleRecordsWritten => 299\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["2001 had 76370 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 7\nnumTasks => 21\nelapsedTime => 19236 (19 s)\nstageDuration => 17758 (18 s)\nexecutorRunTime => 117292 (2.0 min)\nexecutorCpuTime => 14563 (15 s)\nexecutorDeserializeTime => 993 (1.0 s)\nexecutorDeserializeCpuTime => 241 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 1572 (2 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 323 (0.3 s)\nresultSize => 33827 (33.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138412032\nrecordsRead => 3209457\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 299\nshuffleTotalBlocksFetched => 7\nshuffleLocalBlocksFetched => 7\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 20360 (19.0 KB)\nshuffleLocalBytesRead => 20360 (19.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 20360 (19.0 KB)\nshuffleRecordsWritten => 299\n"]}}],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\npart1_QA(spark, \"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\", \"dbfs:/FileStore/tables/ontimeperformance_aircrafts.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b341351-dac1-474f-b331-b47282d5345d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"2001 had 763186 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 7\nnumTasks => 21\nelapsedTime => 128010 (2.1 min)\nstageDuration => 124253 (2.1 min)\nexecutorRunTime => 913455 (15 min)\nexecutorCpuTime => 129905 (2.2 min)\nexecutorDeserializeTime => 2062 (2 s)\nexecutorDeserializeCpuTime => 329 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 13448 (13 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 263 (0.3 s)\nresultSize => 33827 (33.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138412032\nrecordsRead => 32000165\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 319\nshuffleTotalBlocksFetched => 7\nshuffleLocalBlocksFetched => 7\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 21829 (21.0 KB)\nshuffleLocalBytesRead => 21829 (21.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 21829 (21.0 KB)\nshuffleRecordsWritten => 319\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["2001 had 763186 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 7\nnumTasks => 21\nelapsedTime => 128010 (2.1 min)\nstageDuration => 124253 (2.1 min)\nexecutorRunTime => 913455 (15 min)\nexecutorCpuTime => 129905 (2.2 min)\nexecutorDeserializeTime => 2062 (2 s)\nexecutorDeserializeCpuTime => 329 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 13448 (13 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 263 (0.3 s)\nresultSize => 33827 (33.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138412032\nrecordsRead => 32000165\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 319\nshuffleTotalBlocksFetched => 7\nshuffleLocalBlocksFetched => 7\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 21829 (21.0 KB)\nshuffleLocalBytesRead => 21829 (21.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 21829 (21.0 KB)\nshuffleRecordsWritten => 319\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question 1 B"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"346353c4-acad-4cf5-afd5-1ccca134cc4d"}}},{"cell_type":"code","source":["from pyspark.sql.functions import *\ndef q1b(flights_path, airports_path):\n  \n  #Reading in the data\n  flights_df = spark.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(flights_path) \\\n  \n  airports_df = spark.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(airports_path)\n  \n  #Cleaning the column names to remove the extra whitespace\n  replacement = []\n  \n  for i in flights_df.columns:\n    replacement.append(col(i).alias(i.replace(' ', '')))\n  \n  newflightsdf = flights_df.select(*replacement)\n  \n  #Joining the \n  join = newflightsdf.join(airports_df,newflightsdf.destination ==  airports_df.iata,\"leftouter\")\n  newjn = join.filter(join[\"actual_arrival_time\"]>join[\"scheduled_arrival_time\"])\n  df = newjn.groupBy(\"airport\")\\\n  .count()\n  finalresult = df.orderBy(col('count').desc())\n  finalresult = finalresult.select(col(\"airport\").alias(\"airport_name\"), col(\"count\").alias(\"count_of_late_arrivals\"))\n  latest = finalresult.collect()[0]\n  return(\"{} had {} late arrivals\".format(latest[0], latest[1]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5f5f4af-1b82-4ce2-8b06-ba37f86a9dd5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["q1b(f\"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\")\nq1b(f\"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\")\nq1b(f\"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eedf2eb6-1eec-4212-91c5-7d0296ee8918"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nq1b(f\"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d27b5bcb-80b6-4df8-90a0-2a86092b131c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 13\nelapsedTime => 5644 (6 s)\nstageDuration => 4305 (4 s)\nexecutorRunTime => 9196 (9 s)\nexecutorCpuTime => 2188 (2 s)\nexecutorDeserializeTime => 250 (0.3 s)\nexecutorDeserializeCpuTime => 132 (0.1 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 444 (0.4 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 433 (0.4 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 85065728\nrecordsRead => 357951\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2092\nshuffleTotalBlocksFetched => 7\nshuffleLocalBlocksFetched => 7\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 126657 (123.0 KB)\nshuffleLocalBytesRead => 126657 (123.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 71839 (70.0 KB)\nshuffleRecordsWritten => 1223\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 13\nelapsedTime => 5644 (6 s)\nstageDuration => 4305 (4 s)\nexecutorRunTime => 9196 (9 s)\nexecutorCpuTime => 2188 (2 s)\nexecutorDeserializeTime => 250 (0.3 s)\nexecutorDeserializeCpuTime => 132 (0.1 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 444 (0.4 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 433 (0.4 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 85065728\nrecordsRead => 357951\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2092\nshuffleTotalBlocksFetched => 7\nshuffleLocalBlocksFetched => 7\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 126657 (123.0 KB)\nshuffleLocalBytesRead => 126657 (123.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 71839 (70.0 KB)\nshuffleRecordsWritten => 1223\n"]}}],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nq1b(f\"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9284f917-d50a-463a-926d-40d5cf181de4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 23\nelapsedTime => 18064 (18 s)\nstageDuration => 16876 (17 s)\nexecutorRunTime => 113546 (1.9 min)\nexecutorCpuTime => 14387 (14 s)\nexecutorDeserializeTime => 633 (0.6 s)\nexecutorDeserializeCpuTime => 205 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 1995 (2 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1410 (1 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 204472320\nrecordsRead => 3512971\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 5016\nshuffleTotalBlocksFetched => 17\nshuffleLocalBlocksFetched => 17\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 316653 (309.0 KB)\nshuffleLocalBytesRead => 316653 (309.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 169587 (165.0 KB)\nshuffleRecordsWritten => 2706\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 23\nelapsedTime => 18064 (18 s)\nstageDuration => 16876 (17 s)\nexecutorRunTime => 113546 (1.9 min)\nexecutorCpuTime => 14387 (14 s)\nexecutorDeserializeTime => 633 (0.6 s)\nexecutorDeserializeCpuTime => 205 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 1995 (2 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1410 (1 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 204472320\nrecordsRead => 3512971\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 5016\nshuffleTotalBlocksFetched => 17\nshuffleLocalBlocksFetched => 17\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 316653 (309.0 KB)\nshuffleLocalBytesRead => 316653 (309.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 169587 (165.0 KB)\nshuffleRecordsWritten => 2706\n"]}}],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nq1b(f\"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0639aa07-52d3-40b2-9963-04485627eb7c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 23\nelapsedTime => 102870 (1.7 min)\nstageDuration => 101744 (1.7 min)\nexecutorRunTime => 781305 (13 min)\nexecutorCpuTime => 126232 (2.1 min)\nexecutorDeserializeTime => 570 (0.6 s)\nexecutorDeserializeCpuTime => 203 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 12840 (13 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1245 (1 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 204472320\nrecordsRead => 35057032\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 5129\nshuffleTotalBlocksFetched => 17\nshuffleLocalBlocksFetched => 17\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 325050 (317.0 KB)\nshuffleLocalBytesRead => 325050 (317.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 174986 (170.0 KB)\nshuffleRecordsWritten => 2770\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 23\nelapsedTime => 102870 (1.7 min)\nstageDuration => 101744 (1.7 min)\nexecutorRunTime => 781305 (13 min)\nexecutorCpuTime => 126232 (2.1 min)\nexecutorDeserializeTime => 570 (0.6 s)\nexecutorDeserializeCpuTime => 203 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 12840 (13 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1245 (1 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 204472320\nrecordsRead => 35057032\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 5129\nshuffleTotalBlocksFetched => 17\nshuffleLocalBlocksFetched => 17\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 325050 (317.0 KB)\nshuffleLocalBytesRead => 325050 (317.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 174986 (170.0 KB)\nshuffleRecordsWritten => 2770\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question 1 C \nSteven Li 500517721"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7aab286b-2017-482a-8c37-2ddf461711c8"}}},{"cell_type":"code","source":["# Question 1 C Steven Li 500517721\ndef q1c_task(spark_session, airport_path, flight_path):\n    from pyspark.sql import functions as F\n    #import data\n    flight_df = spark_session.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(flight_path)\n    flight_df = clean_column_names(flight_df)\n    flight = flight_df.select(F.col('origin').alias('airport_code'), F.col('carrier_code'))\n    \n    airport_df = spark_session.read.format(\"csv\")\\\n                        .option(\"header\", \"true\")\\\n                        .option(\"inferSchema\", \"true\")\\\n                        .load(airport_path)\n    airport_df = clean_column_names(airport_df) # clean column names\n    airport = airport_df.select(F.col('iata').alias('airport_code'), F.col('state')) # select relevant columns and change col names\n\n    join_df = airport.join(flight, 'airport_code',\"right\") # join for departure\n    group_df = join_df.groupBy(\"state\").count().dropna() # calculate how many flights in each state for departure\n    \n    flight1 = flight_df.select(F.col('destination').alias('airport_code'), F.col('carrier_code')) # select relevant columns and change col names\n    join_df1 = airport.join(flight1, 'airport_code',\"right\") # join for arrival\n    group_df1 = join_df1.groupBy(\"state\").count().dropna() # calculate how many flights in each state for arrival\n    \n    union_df = group_df.union(group_df1) # make arrival and departure together\n    group_df_final = union_df.groupBy(\"state\").sum(\"count\").orderBy(\"sum(count)\").limit(1) # sum up the results \n    group_rdd_final = group_df_final.rdd.collect()\n    # print output\n    for (user, count) in group_rdd_final:\n        print(\"%s had %i flights.\" % (user, count))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92e87498-92bb-4341-9e20-a794f8db1a38"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Output and Spark measure small\nprint(\"small\") \nstagemetrics.begin()\nq1c_task(spark,\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0eb4cbbe-741b-4aff-9636-4743b17c46df"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"small\nDE had 3 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 10\nnumTasks => 17\nelapsedTime => 5073 (5 s)\nstageDuration => 5833 (6 s)\nexecutorRunTime => 13688 (14 s)\nexecutorCpuTime => 2797 (3 s)\nexecutorDeserializeTime => 450 (0.5 s)\nexecutorDeserializeCpuTime => 186 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 0 (0 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 222 (0.2 s)\nresultSize => 30631 (29.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 51511296\nrecordsRead => 538986\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 431\nshuffleTotalBlocksFetched => 9\nshuffleLocalBlocksFetched => 9\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 28045 (27.0 KB)\nshuffleLocalBytesRead => 28045 (27.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 28045 (27.0 KB)\nshuffleRecordsWritten => 431\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["small\nDE had 3 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 10\nnumTasks => 17\nelapsedTime => 5073 (5 s)\nstageDuration => 5833 (6 s)\nexecutorRunTime => 13688 (14 s)\nexecutorCpuTime => 2797 (3 s)\nexecutorDeserializeTime => 450 (0.5 s)\nexecutorDeserializeCpuTime => 186 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 0 (0 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 222 (0.2 s)\nresultSize => 30631 (29.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 51511296\nrecordsRead => 538986\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 431\nshuffleTotalBlocksFetched => 9\nshuffleLocalBlocksFetched => 9\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 28045 (27.0 KB)\nshuffleLocalBytesRead => 28045 (27.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 28045 (27.0 KB)\nshuffleRecordsWritten => 431\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Output and Spark measure medium\nprint(\"medium\")\nstagemetrics.begin()\nq1c_task(spark,\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fb02b9d-8196-454b-b9ff-a5ec9500dc30"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"medium\nAS had 9 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 10\nnumTasks => 32\nelapsedTime => 21028 (21 s)\nstageDuration => 26284 (26 s)\nexecutorRunTime => 139817 (2.3 min)\nexecutorCpuTime => 18485 (18 s)\nexecutorDeserializeTime => 1392 (1 s)\nexecutorDeserializeCpuTime => 346 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 3136 (3 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 842 (0.8 s)\nresultSize => 30631 (29.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 137363456\nrecordsRead => 5320035\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 967\nshuffleTotalBlocksFetched => 19\nshuffleLocalBlocksFetched => 19\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 63162 (61.0 KB)\nshuffleLocalBytesRead => 63162 (61.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 63162 (61.0 KB)\nshuffleRecordsWritten => 967\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["medium\nAS had 9 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 10\nnumTasks => 32\nelapsedTime => 21028 (21 s)\nstageDuration => 26284 (26 s)\nexecutorRunTime => 139817 (2.3 min)\nexecutorCpuTime => 18485 (18 s)\nexecutorDeserializeTime => 1392 (1 s)\nexecutorDeserializeCpuTime => 346 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 3136 (3 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 842 (0.8 s)\nresultSize => 30631 (29.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 137363456\nrecordsRead => 5320035\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 967\nshuffleTotalBlocksFetched => 19\nshuffleLocalBlocksFetched => 19\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 63162 (61.0 KB)\nshuffleLocalBytesRead => 63162 (61.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 63162 (61.0 KB)\nshuffleRecordsWritten => 967\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Output and Spark measure large\nprint(\"large\")\nstagemetrics.begin()\nq1c_task(spark,\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"374875ae-35fc-4971-b85e-fb14ed122b8a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"large\nAS had 138 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 10\nnumTasks => 32\nelapsedTime => 164279 (2.7 min)\nstageDuration => 206962 (3.4 min)\nexecutorRunTime => 1244670 (21 min)\nexecutorCpuTime => 176238 (2.9 min)\nexecutorDeserializeTime => 2118 (2 s)\nexecutorDeserializeCpuTime => 395 (0.4 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 17609 (18 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1412 (1 s)\nresultSize => 30631 (29.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 137363456\nrecordsRead => 53120820\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 967\nshuffleTotalBlocksFetched => 19\nshuffleLocalBlocksFetched => 19\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 63331 (61.0 KB)\nshuffleLocalBytesRead => 63331 (61.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 63331 (61.0 KB)\nshuffleRecordsWritten => 967\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["large\nAS had 138 flights.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 10\nnumTasks => 32\nelapsedTime => 164279 (2.7 min)\nstageDuration => 206962 (3.4 min)\nexecutorRunTime => 1244670 (21 min)\nexecutorCpuTime => 176238 (2.9 min)\nexecutorDeserializeTime => 2118 (2 s)\nexecutorDeserializeCpuTime => 395 (0.4 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 17609 (18 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1412 (1 s)\nresultSize => 30631 (29.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 137363456\nrecordsRead => 53120820\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 967\nshuffleTotalBlocksFetched => 19\nshuffleLocalBlocksFetched => 19\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 63331 (61.0 KB)\nshuffleLocalBytesRead => 63331 (61.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 63331 (61.0 KB)\nshuffleRecordsWritten => 967\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Question 1 D"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c11a6895-d162-4a8c-96c3-c0528b30b701"}}},{"cell_type":"code","source":["def q1_d(spark_session,flights_f,aircrafts_f):\n  from pyspark.sql.functions import desc\n  from pyspark.sql.types import DoubleType \n  from pyspark.sql.functions import col  \n  \n  def clean_column_names(df):\n    tempList = [] #Edit01\n    for col in df.columns:\n        new_name = col.strip()\n        new_name = \"\".join(new_name.split())\n        new_name = new_name.replace('.','') \n        tempList.append(new_name) \n  \n    return df.toDF(*tempList)\n  \n  flights_df = spark_session.read.format(\"csv\")\\\n                          .option(\"header\", \"true\") \\\n                          .option(\"inferSchema\", \"true\") \\\n                          .load(flights_f)\n  F_df = clean_column_names(flights_df)\n  \n  aircrafts_df = spark_session.read.format(\"csv\")\\\n                          .option(\"header\", \"true\")\\\n                          .option(\"inferSchema\", \"true\")\\\n                          .load(aircrafts_f)\n  A_df = clean_column_names(aircrafts_df)\n  \n  join_df = F_df.join(A_df, F_df.tail_number == A_df.tailnum).select('manufacturer','model','tail_number','distance')\n  join_df = join_df.withColumn('distance',col('distance').cast('double'))\n  total_dis = join_df.groupBy('manufacturer','model','tail_number').sum()\n  total_dis = total_dis.sort(desc('sum(distance)'))\n  \n  return 'The ' + total_dis.first()[0] + ' ' + total_dis.first()[1] + ' tail number ' + total_dis.first()[2] + ' flew ' + str(total_dis.first()[3]) + ' miles.'\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2953574a-dbcf-4dd5-a2d7-65da53491365"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nq1_d(spark,\"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\", \"dbfs:/FileStore/tables/ontimeperformance_aircrafts.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46b88d8c-8c16-486e-8385-0348ab3e5a1c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[5]: 'The BOEING 757-222 tail number N544UA flew 49234.0 miles.'","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[5]: 'The BOEING 757-222 tail number N544UA flew 49234.0 miles.'"]}}],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nq1_d(spark,\"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\", \"dbfs:/FileStore/tables/ontimeperformance_aircrafts.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d89e221-eaf3-45d4-95cf-b6f7ac643ca9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nq1_d(spark,\"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\", \"dbfs:/FileStore/tables/ontimeperformance_aircrafts.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aeabb195-a33e-43a8-8f00-be35c39de58e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Question 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ed66a93-f4a0-4111-ab93-b5da915cdcaf"}}},{"cell_type":"markdown","source":["Q2 Dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da507ce1-063c-4328-8727-fc331237acfb"}}},{"cell_type":"code","source":["import pyspark.sql.functions as F\nfrom pyspark.sql import Window\nfrom pyspark.sql.functions import *\n\ndef late_arrivals(flights_path, airlines_path):\n  \n  airlines_df = spark.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(airlines_path)\n  \n  \n  flights_df = spark.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(flights_path)\n  #Cleaning the column names\n  replacement = []\n  for i in flights_df.columns:\n      replacement.append(col(i).alias(i.replace(' ', '')))\n  \n  newflightsdf = flights_df.select(*replacement)\n  \n  #Joining both datasets using the column carrier_code\n  result = newflightsdf.join(airlines_df, 'carrier_code')\n  \n  #Using spark.sql.functions as F to find late arrivals, early arrivals and on time arrivals and the make them into categories 1,-1 and 0 respectively.\n  latearrivals = result.select(result.carrier_code, F.when(result.actual_arrival_time > result.scheduled_arrival_time, 1).when(result.actual_arrival_time < result.scheduled_arrival_time, -1).otherwise(0))\n  \n  \n  #Renaming the columns required\n  latenew = latearrivals.select( col('carrier_code').alias('carrier_code'),col(\"CASE WHEN (actual_arrival_time > scheduled_arrival_time) THEN 1 WHEN (actual_arrival_time < scheduled_arrival_time) THEN -1 ELSE 0 END\").alias(\"arrival_cat\"))\n  \n  #Grouping by each category and the carrier code to find the count of late arrivals per \n  latenew = latenew.groupBy(latenew.arrival_cat,latenew.carrier_code).count().orderBy(latenew.carrier_code,latenew.arrival_cat)\n  \n  # TO find the percentage for each airline we have to create a window. Windows allow us to aggregate the data for all instances of carrier_code. So the count() of 1,-1 and 0 in our case. \n  w = Window.partitionBy(\"carrier_code\").orderBy(F.col(\"carrier_code\"))\n  \n  #Calculating the percentage of each category 1,-1 and 0 over the carrier code and storing the percentage in the column 'Percentage'\n  finaldf = latenew.withColumn(\"late\",F.collect_list(F.col('count')).over(w)).withColumn('Percentage',100*F.col('count')/F.sum('count').over(w))\n  \n  \n  #Filtering for just the late arrivals.\n  summarydf = finaldf.filter(F.col('arrival_cat') == 1).sort(desc('Percentage'))\n  answerdf = summarydf.join(airlines_df,\n                            'carrier_code').select(col('name'),col('Percentage').alias('rate_arrived_late')).sort(desc('rate_arrived_late'))\n  \n  return(answerdf)\n\n\n# To calculate the late departures %, the same is done as late_arrivals except that we change the columns to actual_departure_time and scheduled_departure_time.\n\ndef late_departures(flights_path, airlines_path):\n  \n  airlines_df = spark.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(airlines_path)\n  \n  \n  flights_df = spark.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(flights_path)\n  \n  replacement = []\n  for i in flights_df.columns:\n      replacement.append(col(i).alias(i.replace(' ', '')))\n  \n  newflightsdf = flights_df.select(*replacement)\n  result = newflightsdf.join(airlines_df, 'carrier_code')\n  latearrivals = result.select(result.carrier_code, F.when(result.actual_departure_time > result.scheduled_depature_time, 1).when(result.actual_departure_time < result.scheduled_depature_time, -1).otherwise(0))\n  \n  latenew = latearrivals.select( col('carrier_code').alias('carrier_code'),col(\"CASE WHEN (actual_departure_time > scheduled_depature_time) THEN 1 WHEN (actual_departure_time < scheduled_depature_time) THEN -1 ELSE 0 END\").alias(\"arrival_cat\"))\n  latenew = latenew.groupBy(latenew.arrival_cat,latenew.carrier_code).count().orderBy(latenew.carrier_code,latenew.arrival_cat)\n  \n\n  w = Window.partitionBy(\"carrier_code\").orderBy(F.col(\"carrier_code\"))\n  finaldf = latenew.withColumn(\"late\",F.collect_list(F.col('count')).over(w)).withColumn('Percentage',100*F.col('count')/F.sum('count').over(w))\n  \n    \n  summarydf = finaldf.filter(F.col('arrival_cat') == 1).sort(desc('Percentage'))\n  answerdf = summarydf.join(airlines_df,\n                            'carrier_code').select(col('name'),col('Percentage').alias('rate_arrived_late')).sort(desc('rate_arrived_late'))\n  \n  return(answerdf)\n\n\ndef final_answer(flights_path, airlines_path):\n  arrive = late_arrivals(flights_path, airlines_path)\n  dep = late_departures(flights_path, airlines_path)\n  arrival_collection = arrive.collect()[0]\n  dep_collection = dep.collect()[0]\n  return(\"{} departed late {}% of the time.{} arrived late {}% of the time\".format(dep_collection[0], dep_collection[1],\n                                                                                   arrival_collection[0],arrival_collection[1]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e67488b8-0d4f-4e8d-93a2-f382e7b3dfb1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["final_answer(f\"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airlines.csv\")\nfinal_answer(f\"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airlines.csv\")\nfinal_answer(f\"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airlines.csv\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eca26eb7-9f6b-4197-8fa2-b8d1cbaebc1d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nfinal_answer(f\"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airlines.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2df8d30a-ba81-4015-810b-33e5d0947c0f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 26\nnumTasks => 34\nelapsedTime => 9750 (10 s)\nstageDuration => 6869 (7 s)\nexecutorRunTime => 11237 (11 s)\nexecutorCpuTime => 3850 (4 s)\nexecutorDeserializeTime => 615 (0.6 s)\nexecutorDeserializeCpuTime => 406 (0.4 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 120 (0.1 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 158 (0.2 s)\nresultSize => 14412 (14.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 52002816\nrecordsRead => 712908\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 1304\nshuffleTotalBlocksFetched => 20\nshuffleLocalBlocksFetched => 20\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 82036 (80.0 KB)\nshuffleLocalBytesRead => 82036 (80.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 50763 (49.0 KB)\nshuffleRecordsWritten => 775\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 26\nnumTasks => 34\nelapsedTime => 9750 (10 s)\nstageDuration => 6869 (7 s)\nexecutorRunTime => 11237 (11 s)\nexecutorCpuTime => 3850 (4 s)\nexecutorDeserializeTime => 615 (0.6 s)\nexecutorDeserializeCpuTime => 406 (0.4 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 120 (0.1 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 158 (0.2 s)\nresultSize => 14412 (14.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 52002816\nrecordsRead => 712908\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 1304\nshuffleTotalBlocksFetched => 20\nshuffleLocalBlocksFetched => 20\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 82036 (80.0 KB)\nshuffleLocalBytesRead => 82036 (80.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 50763 (49.0 KB)\nshuffleRecordsWritten => 775\n"]}}],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nfinal_answer(f\"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airlines.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"178d2d69-3757-49e9-930f-724d7af1f097"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 26\nnumTasks => 54\nelapsedTime => 35304 (35 s)\nstageDuration => 32067 (32 s)\nexecutorRunTime => 200313 (3.3 min)\nexecutorCpuTime => 27761 (28 s)\nexecutorDeserializeTime => 1610 (2 s)\nexecutorDeserializeCpuTime => 673 (0.7 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 6365 (6 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1366 (1 s)\nresultSize => 27424 (26.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138674176\nrecordsRead => 7087640\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2204\nshuffleTotalBlocksFetched => 40\nshuffleLocalBlocksFetched => 40\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 146801 (143.0 KB)\nshuffleLocalBytesRead => 146801 (143.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 83242 (81.0 KB)\nshuffleRecordsWritten => 1226\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 26\nnumTasks => 54\nelapsedTime => 35304 (35 s)\nstageDuration => 32067 (32 s)\nexecutorRunTime => 200313 (3.3 min)\nexecutorCpuTime => 27761 (28 s)\nexecutorDeserializeTime => 1610 (2 s)\nexecutorDeserializeCpuTime => 673 (0.7 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 6365 (6 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1366 (1 s)\nresultSize => 27424 (26.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138674176\nrecordsRead => 7087640\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2204\nshuffleTotalBlocksFetched => 40\nshuffleLocalBlocksFetched => 40\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 146801 (143.0 KB)\nshuffleLocalBytesRead => 146801 (143.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 83242 (81.0 KB)\nshuffleRecordsWritten => 1226\n"]}}],"execution_count":0},{"cell_type":"code","source":["stagemetrics.begin()\nfinal_answer(f\"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\", f\"dbfs:/FileStore/tables/ontimeperformance_airlines.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"861433b7-52db-4b7d-8031-a90267d1566c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 26\nnumTasks => 54\nelapsedTime => 210424 (3.5 min)\nstageDuration => 207446 (3.5 min)\nexecutorRunTime => 1574352 (26 min)\nexecutorCpuTime => 251044 (4.2 min)\nexecutorDeserializeTime => 1387 (1 s)\nexecutorDeserializeCpuTime => 595 (0.6 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 30662 (31 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1350 (1 s)\nresultSize => 27424 (26.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138674176\nrecordsRead => 70822020\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2204\nshuffleTotalBlocksFetched => 40\nshuffleLocalBlocksFetched => 40\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 147403 (143.0 KB)\nshuffleLocalBytesRead => 147403 (143.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 83573 (81.0 KB)\nshuffleRecordsWritten => 1226\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 26\nnumTasks => 54\nelapsedTime => 210424 (3.5 min)\nstageDuration => 207446 (3.5 min)\nexecutorRunTime => 1574352 (26 min)\nexecutorCpuTime => 251044 (4.2 min)\nexecutorDeserializeTime => 1387 (1 s)\nexecutorDeserializeCpuTime => 595 (0.6 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 30662 (31 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 1350 (1 s)\nresultSize => 27424 (26.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 138674176\nrecordsRead => 70822020\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2204\nshuffleTotalBlocksFetched => 40\nshuffleLocalBlocksFetched => 40\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 147403 (143.0 KB)\nshuffleLocalBytesRead => 147403 (143.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 83573 (81.0 KB)\nshuffleRecordsWritten => 1226\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Question 3"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70455547-2a84-4cdf-b6ca-f7d283c39ede"}}},{"cell_type":"markdown","source":["Q3 Dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f3f755b-3ccc-4bdc-abe4-2b7fcbbc9673"}}},{"cell_type":"code","source":["#Q3 DATAFRAME\ndef q3(spark_session, airport_path, flight_path):\n    from pyspark.sql import functions as F\n    from pyspark.sql.functions import countDistinct\n    from pyspark.sql.functions import avg\n\n    # import dataset\n    flight_df = spark_session.read.format(\"csv\") \\\n                        .option(\"header\", \"true\") \\\n                        .option(\"inferSchema\", \"true\") \\\n                        .load(flight_path)\n    flight_df = clean_column_names(flight_df)\n    flight = flight_df.select(F.col('origin').alias('airport_code'), F.col('carrier_code'))\n\n    airport_df = spark_session.read.format(\"csv\")\\\n                        .option(\"header\", \"true\")\\\n                        .option(\"inferSchema\", \"true\")\\\n                        .load(airport_path)\n    airport_df = clean_column_names(airport_df) # cleaning column names\n\n    avedistance = flight_df.groupBy('origin').agg({\"distance\": \"sum\"}).select(avg(\"sum(distance)\")).collect() # calculating the average distance\n    for row in avedistance: # make the average distance useable for later filter\n        avedistance = (\"%s\" % (float(row[\"avg(sum(distance))\"])))\n    avedistance = float(avedistance)\n\n    flight = flight_df.select(F.col('origin').alias('airport_code'), F.col('distance')) # exacting different components from each dataframe to prepare for later aggregration and join\n    flight1 = flight_df.select(F.col('origin').alias('airport_code'), F.col('carrier_code'))\n    airport = airport_df.select(F.col('iata').alias('airport_code'), F.col('airport'))\n\n    airport_group = flight.groupBy(\"airport_code\").agg({'distance':'sum'}) \n    filter_airport = airport_group.filter(airport_group[\"sum(distance)\"] > avedistance) # finding the airports which are greater than the average distance\n\n    airport_count = flight1.groupBy('airport_code').agg(countDistinct(\"carrier_code\")) # counting the unique airlines for each airport\n\n    join_df = filter_airport.join(airport_count,'airport_code','left') \n    output = join_df.join(airport,'airport_code','left').orderBy(\"count(carrier_code)\").limit(1).collect() # join everything together, ordering the number of airlines and only allow the first result\n\n#printing the output\n    for (airport_code, distance, carrier_code, airport) in output:\n        print(\"%s (%s) flew %s, which is more than %d. Only %s flew out of this airport.\" % (airport, airport_code, distance, avedistance, carrier_code))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc7ce0c4-a905-471b-9234-c383f91aef77"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Outputs and spark measure small\nprint(\"small\")\nstagemetrics.begin()\nq3(spark, \"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f87f562-3d56-404c-a401-f1828d69eb6d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"small\nDallas Love  (DAL) flew 617378.0, which is more than 335255. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 13\nnumTasks => 21\nelapsedTime => 7486 (7 s)\nstageDuration => 8542 (9 s)\nexecutorRunTime => 18439 (18 s)\nexecutorCpuTime => 3738 (4 s)\nexecutorDeserializeTime => 559 (0.6 s)\nexecutorDeserializeCpuTime => 169 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 37 (37 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 794 (0.8 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 51118080\nrecordsRead => 716396\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 7670\nshuffleTotalBlocksFetched => 11\nshuffleLocalBlocksFetched => 11\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 216977 (211.0 KB)\nshuffleLocalBytesRead => 216977 (211.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 216977 (211.0 KB)\nshuffleRecordsWritten => 7670\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["small\nDallas Love  (DAL) flew 617378.0, which is more than 335255. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 13\nnumTasks => 21\nelapsedTime => 7486 (7 s)\nstageDuration => 8542 (9 s)\nexecutorRunTime => 18439 (18 s)\nexecutorCpuTime => 3738 (4 s)\nexecutorDeserializeTime => 559 (0.6 s)\nexecutorDeserializeCpuTime => 169 (0.2 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 37 (37 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 794 (0.8 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 51118080\nrecordsRead => 716396\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 7670\nshuffleTotalBlocksFetched => 11\nshuffleLocalBlocksFetched => 11\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 216977 (211.0 KB)\nshuffleLocalBytesRead => 216977 (211.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 216977 (211.0 KB)\nshuffleRecordsWritten => 7670\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Outputs and spark measure medium\nprint(\"medium\")\nstagemetrics.begin()\nq3(spark, \"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f82a92c-83b1-4052-8d32-c3985d67632c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"medium\nDallas Love  (DAL) flew 6007536.0, which is more than 3148300. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 13\nnumTasks => 41\nelapsedTime => 28997 (29 s)\nstageDuration => 46387 (46 s)\nexecutorRunTime => 190932 (3.2 min)\nexecutorCpuTime => 24927 (25 s)\nexecutorDeserializeTime => 1253 (1 s)\nexecutorDeserializeCpuTime => 324 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 2104 (2 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 2632 (3 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 136314880\nrecordsRead => 7091128\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 17988\nshuffleTotalBlocksFetched => 26\nshuffleLocalBlocksFetched => 26\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 523812 (511.0 KB)\nshuffleLocalBytesRead => 523812 (511.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 523812 (511.0 KB)\nshuffleRecordsWritten => 17988\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["medium\nDallas Love  (DAL) flew 6007536.0, which is more than 3148300. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 13\nnumTasks => 41\nelapsedTime => 28997 (29 s)\nstageDuration => 46387 (46 s)\nexecutorRunTime => 190932 (3.2 min)\nexecutorCpuTime => 24927 (25 s)\nexecutorDeserializeTime => 1253 (1 s)\nexecutorDeserializeCpuTime => 324 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 2104 (2 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 2632 (3 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 136314880\nrecordsRead => 7091128\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 17988\nshuffleTotalBlocksFetched => 26\nshuffleLocalBlocksFetched => 26\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 523812 (511.0 KB)\nshuffleLocalBytesRead => 523812 (511.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 523812 (511.0 KB)\nshuffleRecordsWritten => 17988\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Outputs and spark measure large\nprint(\"large\")\nstagemetrics.begin()\nq3(spark, \"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c44f281e-e66f-4951-aa77-be946cf09cb7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"large\nDallas Love  (DAL) flew 59468215.0, which is more than 30860081. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 13\nnumTasks => 41\nelapsedTime => 183498 (3.1 min)\nstageDuration => 307731 (5.1 min)\nexecutorRunTime => 1404898 (23 min)\nexecutorCpuTime => 218775 (3.6 min)\nexecutorDeserializeTime => 1428 (1 s)\nexecutorDeserializeCpuTime => 315 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 14790 (15 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 3329 (3 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 136314880\nrecordsRead => 70825508\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 18353\nshuffleTotalBlocksFetched => 26\nshuffleLocalBlocksFetched => 26\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 531395 (518.0 KB)\nshuffleLocalBytesRead => 531395 (518.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 531395 (518.0 KB)\nshuffleRecordsWritten => 18353\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["large\nDallas Love  (DAL) flew 59468215.0, which is more than 30860081. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 13\nnumTasks => 41\nelapsedTime => 183498 (3.1 min)\nstageDuration => 307731 (5.1 min)\nexecutorRunTime => 1404898 (23 min)\nexecutorCpuTime => 218775 (3.6 min)\nexecutorDeserializeTime => 1428 (1 s)\nexecutorDeserializeCpuTime => 315 (0.3 s)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 14790 (15 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 3329 (3 s)\nresultSize => 76980 (75.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 136314880\nrecordsRead => 70825508\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 18353\nshuffleTotalBlocksFetched => 26\nshuffleLocalBlocksFetched => 26\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 531395 (518.0 KB)\nshuffleLocalBytesRead => 531395 (518.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 531395 (518.0 KB)\nshuffleRecordsWritten => 18353\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Q3 RDD"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cb15ee1-62ce-48b2-9abc-cc23612c9000"}}},{"cell_type":"code","source":["#Q3 RDD\ndef q3_rdd(airport_path, flight_path):\n    #data import\n    flight_rdd = spark.sparkContext.textFile(flight_path) \\\n                                 .map(lambda x: x.split(\",\")) \\\n                                 .filter(lambda x: x[0] != \"carrier_code\") # ignore header line\n\n    airport_rdd = spark.sparkContext.textFile(airport_path) \\\n                                 .map(lambda x: x.split(\",\")) \\\n                                 .filter(lambda x: x[0] != \"iata\") # ignore header line\n\n    rdd_group = flight_rdd.map(lambda x:(x[3],float(x[10]))) # turn distance into float\n    flight_avg = rdd_group.reduceByKey(lambda x,y: x+y).map(lambda x: x[1]).mean() # calculate the mean distance\n\n    rdd_agg = rdd_group.reduceByKey(lambda x,y: x+y).filter(lambda x: x[1]>flight_avg) # summing the distance for each airport and only left the airport greater than the average distance\n\n    rdd_count = flight_rdd.map(lambda x: (x[3],x[0])).groupByKey().mapValues(lambda vals: len(set(vals))) # count the number of unique airline\n\n    join_rdd = rdd_count.join(rdd_agg).join(airport_rdd).sortBy(lambda x: x[1][0]).collect() # join the count of airline, the distance for the airport and airport name together\n    \n    # loop to get the final output\n    for (airport_code, nums) in join_rdd:\n        print(\"%s (%s) flew %s, which is more than %s. Only %s flew out of this airport.\" % (nums[1], airport_code, nums[0][1], flight_avg, nums[0][0]))\n        break"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9102dec-a252-4e66-b02d-fede0caecfce"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Outputs and spark measure small\nprint(\"small\")\nstagemetrics.begin()\nq3_rdd(\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_small.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16dc3171-5fba-4c88-b327-86bb25785697"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"small\nDallas Love  (DAL) flew 617378.0, which is more than 335255.91773778934. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 28\nelapsedTime => 4745 (5 s)\nstageDuration => 6367 (6 s)\nexecutorRunTime => 13008 (13 s)\nexecutorCpuTime => 301 (0.3 s)\nexecutorDeserializeTime => 130 (0.1 s)\nexecutorDeserializeCpuTime => 65 (65 ms)\nresultSerializationTime => 5 (5 ms)\njvmGCTime => 0 (0 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 37 (37 ms)\nresultSize => 11577 (11.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 0\nrecordsRead => 535610\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 292\nshuffleTotalBlocksFetched => 64\nshuffleLocalBlocksFetched => 64\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 514856 (502.0 KB)\nshuffleLocalBytesRead => 514856 (502.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 390324 (381.0 KB)\nshuffleRecordsWritten => 156\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["small\nDallas Love  (DAL) flew 617378.0, which is more than 335255.91773778934. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 28\nelapsedTime => 4745 (5 s)\nstageDuration => 6367 (6 s)\nexecutorRunTime => 13008 (13 s)\nexecutorCpuTime => 301 (0.3 s)\nexecutorDeserializeTime => 130 (0.1 s)\nexecutorDeserializeCpuTime => 65 (65 ms)\nresultSerializationTime => 5 (5 ms)\njvmGCTime => 0 (0 ms)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 37 (37 ms)\nresultSize => 11577 (11.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 0\nrecordsRead => 535610\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 292\nshuffleTotalBlocksFetched => 64\nshuffleLocalBlocksFetched => 64\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 514856 (502.0 KB)\nshuffleLocalBytesRead => 514856 (502.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 390324 (381.0 KB)\nshuffleRecordsWritten => 156\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Outputs and spark measure medium\nprint(\"medium\")\nstagemetrics.begin()\nq3_rdd(\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_medium.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78b6f7ee-56dd-4e0f-9cf2-d7c8d5e8c9fc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"medium\nDallas Love  (DAL) flew 6007536.0, which is more than 3148300.7699757884. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 28\nelapsedTime => 25241 (25 s)\nstageDuration => 40639 (41 s)\nexecutorRunTime => 81310 (1.4 min)\nexecutorCpuTime => 268 (0.3 s)\nexecutorDeserializeTime => 135 (0.1 s)\nexecutorDeserializeCpuTime => 58 (58 ms)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 396 (0.4 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 23 (23 ms)\nresultSize => 11626 (11.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 0\nrecordsRead => 5316659\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 292\nshuffleTotalBlocksFetched => 64\nshuffleLocalBlocksFetched => 64\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 1816556 (1773.0 KB)\nshuffleLocalBytesRead => 1816556 (1773.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 1691922 (1652.0 KB)\nshuffleRecordsWritten => 156\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["medium\nDallas Love  (DAL) flew 6007536.0, which is more than 3148300.7699757884. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 28\nelapsedTime => 25241 (25 s)\nstageDuration => 40639 (41 s)\nexecutorRunTime => 81310 (1.4 min)\nexecutorCpuTime => 268 (0.3 s)\nexecutorDeserializeTime => 135 (0.1 s)\nexecutorDeserializeCpuTime => 58 (58 ms)\nresultSerializationTime => 0 (0 ms)\njvmGCTime => 396 (0.4 s)\nshuffleFetchWaitTime => 0 (0 ms)\nshuffleWriteTime => 23 (23 ms)\nresultSize => 11626 (11.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 0\nrecordsRead => 5316659\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 292\nshuffleTotalBlocksFetched => 64\nshuffleLocalBlocksFetched => 64\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 1816556 (1773.0 KB)\nshuffleLocalBytesRead => 1816556 (1773.0 KB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 1691922 (1652.0 KB)\nshuffleRecordsWritten => 156\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Outputs and spark measure large\nprint(\"large\")\nstagemetrics.begin()\nq3_rdd(\"dbfs:/FileStore/tables/ontimeperformance_airports.csv\", \"dbfs:/FileStore/tables/ontimeperformance_flights_large.csv\")\nstagemetrics.end()\nstagemetrics.print_report()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6743c278-2af5-4c24-9d50-8032feecac46"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"large\nDallas Love  (DAL) flew 59468215.0, which is more than 30860081.874109264. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 154\nelapsedTime => 261348 (4.4 min)\nstageDuration => 351856 (5.9 min)\nexecutorRunTime => 2067052 (34 min)\nexecutorCpuTime => 3001 (3 s)\nexecutorDeserializeTime => 949 (0.9 s)\nexecutorDeserializeCpuTime => 373 (0.4 s)\nresultSerializationTime => 3 (3 ms)\njvmGCTime => 17704 (18 s)\nshuffleFetchWaitTime => 7 (7 ms)\nshuffleWriteTime => 753 (0.8 s)\nresultSize => 39798 (38.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 0\nrecordsRead => 53117444\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2297\nshuffleTotalBlocksFetched => 1103\nshuffleLocalBlocksFetched => 1103\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 4518680 (4.0 MB)\nshuffleLocalBytesRead => 4518680 (4.0 MB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 4365816 (4.0 MB)\nshuffleRecordsWritten => 1825\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["large\nDallas Love  (DAL) flew 59468215.0, which is more than 30860081.874109264. Only 10 flew out of this airport.\n\nScheduling mode = FAIR\nSpark Context default degree of parallelism = 8\nAggregated Spark stage metrics:\nnumStages => 9\nnumTasks => 154\nelapsedTime => 261348 (4.4 min)\nstageDuration => 351856 (5.9 min)\nexecutorRunTime => 2067052 (34 min)\nexecutorCpuTime => 3001 (3 s)\nexecutorDeserializeTime => 949 (0.9 s)\nexecutorDeserializeCpuTime => 373 (0.4 s)\nresultSerializationTime => 3 (3 ms)\njvmGCTime => 17704 (18 s)\nshuffleFetchWaitTime => 7 (7 ms)\nshuffleWriteTime => 753 (0.8 s)\nresultSize => 39798 (38.0 KB)\ndiskBytesSpilled => 0 (0 Bytes)\nmemoryBytesSpilled => 0 (0 Bytes)\npeakExecutionMemory => 0\nrecordsRead => 53117444\nbytesRead => 0 (0 Bytes)\nrecordsWritten => 0\nbytesWritten => 0 (0 Bytes)\nshuffleRecordsRead => 2297\nshuffleTotalBlocksFetched => 1103\nshuffleLocalBlocksFetched => 1103\nshuffleRemoteBlocksFetched => 0\nshuffleTotalBytesRead => 4518680 (4.0 MB)\nshuffleLocalBytesRead => 4518680 (4.0 MB)\nshuffleRemoteBytesRead => 0 (0 Bytes)\nshuffleRemoteBytesReadToDisk => 0 (0 Bytes)\nshuffleBytesWritten => 4365816 (4.0 MB)\nshuffleRecordsWritten => 1825\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3404 assignment","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3520558611550218}},"nbformat":4,"nbformat_minor":0}
